{
  "cells": [
    {
      "metadata": {
        "_uuid": "cb452123f16c92b6d0b9d2199b29f7a4d9f8bea6"
      },
      "cell_type": "markdown",
      "source": "# Alexnet Architecture"
    },
    {
      "metadata": {
        "_uuid": "8d38b05f4ce087c69bcae46be6155b62a7792105"
      },
      "cell_type": "markdown",
      "source": "AlexNet is the name of a convolutional neural network, invented by **Alex Krizhevsky**, **Ilya Sutskever** and **Geoffrey Hinton**. AlexNet has had a large impact on the field of machine learning, specifically in the application of deep learning to machine vision. As of 2018 it has been cited over 25,000 times.\n\nAlexNet competed in the [ImageNet Large Scale Visual Recognition Challenge](https://en.wikipedia.org/wiki/ImageNet#ImageNet_Challenge) in 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points lower than that of the runner up. The original paper's primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of GPUs during training.\n\nAlexNet contained eight layers; the first five were convolutional layers, and the last three were fully connected layers. It used the non-saturating `ReLU` activation function, which showed improved training performance over `tanh` and `sigmoid`.\n\n![](https://github.com/Koderunners/Convolutional-Neural-Networks/blob/master/Images/Alexnet.png)\n\n\nThe current implementation has been made using Tensorflow which utilizes 6 GB of Nvidia Tesla K80 GPU provided in Kaggle Kernels. This kernel was written by [Soumik Rakshit](https://www.kaggle.com/soumikrakshit) and [Sohom Dey](https://www.kaggle.com/sohom17d)."
    },
    {
      "metadata": {
        "_uuid": "8cf82a475cadeadc2687bc53bef02627bf782fec"
      },
      "cell_type": "markdown",
      "source": "## Importing Libraries"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings('ignore')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport cv2, os",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e24edfd1f23c8b94ba0bac7f48dee517184b032"
      },
      "cell_type": "markdown",
      "source": "## Read Dataset"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0b6185d01e91c3967db1eca2b18ffef2117fe38"
      },
      "cell_type": "code",
      "source": "train_dir = '../input/asl_alphabet_train/asl_alphabet_train/'\ntrain_folders = os.listdir(train_dir)\ntest_dir = '../input/asl_alphabet_test/asl_alphabet_test/'\ntest_files = os.listdir(test_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e896cf03a073b67e29ed0ea9d1ad3303a89378e"
      },
      "cell_type": "code",
      "source": "x_train, y_train = [], []\nfor folder in train_folders:\n    files = os.listdir(train_dir + folder)\n    print('Reading images from ' + train_dir + folder + '/ ...')\n    for file in files[:1000]:\n        img = cv2.imread(train_dir + folder + '/' + file)\n        img = cv2.resize(img, (227, 227))\n        x_train.append(img)\n        y_train.append(folder)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "450c435e4ebac23841149248f6d742f1e08f7d1d"
      },
      "cell_type": "code",
      "source": "len(x_train), x_train[0].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6808ce35b9ab623483c2fe9a2f49a6a496902b18"
      },
      "cell_type": "code",
      "source": "len(y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21286e7cde9891eac40c5a32dcc869f11d1d741f"
      },
      "cell_type": "code",
      "source": "x_test, y_test = [], []\nfor file in test_files:\n    img = cv2.imread(test_dir + file)\n    img = cv2.resize(img, (227, 227))\n    x_test.append(img)\n    y_test.append(file.split('_')[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62229833596941615fc68f85885bef315a2f2c88"
      },
      "cell_type": "code",
      "source": "len(x_test), x_test[0].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "414e3b19ea9e4e9cbfa4c67c2a181875deeb2fcb"
      },
      "cell_type": "code",
      "source": "len(y_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89a26fb1d4d8a676bb053fe25dc4fa969ed68c18"
      },
      "cell_type": "markdown",
      "source": "## Data Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8fc4d352eafba9ebd7a2ed2005ba828d7dbc1518"
      },
      "cell_type": "code",
      "source": "# LabelEncoding\ny_test_encoded = np.array(list(range(len(y_test))))\ny_train_encoded = np.array([y_test.index(i) if i != 'del' else 29 for i in y_train])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10b414da8bf2a891f525589d7d3fdd0924cc0a80"
      },
      "cell_type": "code",
      "source": "y_test_encoded = np.eye(30)[y_test_encoded]\ny_train_encoded = np.eye(30)[y_train_encoded]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3066ecd34d8e25d1dbf90d8139b15ae591094dd8"
      },
      "cell_type": "code",
      "source": "y_train_encoded.shape, y_test_encoded.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "418887b5748020f100f68d2ace1f0fd6e63436ca"
      },
      "cell_type": "markdown",
      "source": "## Data Visualization"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c25a0b24ad933aea445c0d53eb927b8126aceba1"
      },
      "cell_type": "code",
      "source": "def next_batch(batch_size, data, labels):\n    idx = np.arange(0, len(data))\n    np.random.shuffle(idx)\n    idx = idx[: batch_size]\n    data_shuffle = [data[i] for i in idx]\n    labels_shuffle = [labels[i] for i in idx]\n    return np.asarray(data_shuffle), np.asarray(labels_shuffle)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a373ba21959ec689e4beef98513d0eb10265d9dd"
      },
      "cell_type": "code",
      "source": "def display_images(data, title, display_label = True):\n    x, y = data\n    fig, axes = plt.subplots(2, 6, figsize = (18, 5))\n    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n    fig.suptitle(title, fontsize = 18)\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(x[i])\n        if display_label:\n            ax.set_xlabel(y[i])\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "643112e977e0a47bb36fbba360a79b06c31bbfcd"
      },
      "cell_type": "code",
      "source": "display_images(next_batch(12, x_train, y_train), 'Training Images')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3652cd3643c149f5165d60bb38a359dbc51bf685"
      },
      "cell_type": "code",
      "source": "display_images(next_batch(12, x_test, y_test), 'Test Images')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5c95e2d52ee4d33eaa5fe4413a58902d02ef4fa"
      },
      "cell_type": "markdown",
      "source": "## Alexnet Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec8ab981a381a3d65bde300ed305fd12505b185f"
      },
      "cell_type": "code",
      "source": "# Training Hyperparameters\nlearning_rate = 0.001\nepochs = 5000\nbatch_size = 128\ndisplay_step = 200",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b67a042032ea5ae5eec536debff2a2003bbd273"
      },
      "cell_type": "code",
      "source": "height = 227\nwidth = 227\nn_channels = 3\nn_classes = 30",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "119e555c37888f7b85b7cc15ce50a04b03d4a888"
      },
      "cell_type": "code",
      "source": "X = tf.placeholder(tf.float32, shape = [None, height, width, n_channels])\nY = tf.placeholder(tf.float32, shape = [None, n_classes])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21a597727137f7d9d23a097d44ba289d06259960"
      },
      "cell_type": "code",
      "source": "weights = {\n    # Convolutional Layer 1: 11x11 filters, 3 input channels, 96 output channels\n    'w1' : tf.Variable(tf.random_normal([11, 11, 3, 96])), \n    # Convolutional Layer 2: 5x5 filters, 96 input channels, 256 output channels\n    'w2' : tf.Variable(tf.random_normal([5, 5, 96, 256])),\n    # Convolutional Layer 3: 3x3 filters, 256 input channels, 384 output channels\n    'w3' : tf.Variable(tf.random_normal([3, 3, 256, 384])),\n    # Convolutional Layer 4: 3x3 filters, 384 input channels, 384 output channels\n    'w4' : tf.Variable(tf.random_normal([3, 3, 384, 384])),\n    # Convolutional Layer 5: 3x3 filters, 384 input channels, 256 output channels\n    'w5' : tf.Variable(tf.random_normal([3, 3, 384, 256])),\n    # Fully Connected Layer 1: 9216 input channels, 4096 output channels\n    'w6' : tf.Variable(tf.random_normal([9216, 4096])),\n    # Fully Connected Layer 2: 4096 input channels, 4096 output channels\n    'w7' : tf.Variable(tf.random_normal([4096, 4096])),\n    # Fully Connected Layer 3: 4096 input channels, 30(number of classes) output channels\n    'w8' : tf.Variable(tf.random_normal([4096, n_classes]))\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e2b840360aab6f3deb9d1002bb2a9d9f52799c0"
      },
      "cell_type": "code",
      "source": "biases = {\n    'b1' : tf.Variable(tf.random_normal([96])),\n    'b2' : tf.Variable(tf.random_normal([256])),\n    'b3' : tf.Variable(tf.random_normal([384])),\n    'b4' : tf.Variable(tf.random_normal([384])),\n    'b5' : tf.Variable(tf.random_normal([256])),\n    'b6' : tf.Variable(tf.random_normal([4096])),\n    'b7' : tf.Variable(tf.random_normal([4096])),\n    'b8' : tf.Variable(tf.random_normal([n_classes]))\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f85b996d4859ddd23eac33f5fe3dbd266b2efef"
      },
      "cell_type": "code",
      "source": "# Wrapper function for creating a Convolutional Layer\ndef conv2d(x, W, b, strides = 1, padding = 'SAME'):\n    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = padding)\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8bf489e488ca3d9e5acefe82a5d54dcb1ddff8c"
      },
      "cell_type": "code",
      "source": "# Wrapper function for creating a Pooling Layer\ndef maxpool2d(x, k = 2, padding = 'VALID'):\n    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = padding)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a89a355f1cd74582f135b387cd9c71966bf38e6"
      },
      "cell_type": "code",
      "source": "def alexnet(x, w, b):\n    x = tf.reshape(x, shape = [-1, 227, 227, 3])\n    \n    # Layer 1\n    conv1 = conv2d(x, w['w1'], b['b1'], strides = 4, padding = 'VALID') # Convolution\n    conv1 = maxpool2d(conv1) # Pooling\n    \n    # Layer 2\n    conv2 = conv2d(conv1, w['w2'], b['b2']) # Convolution\n    conv2 = maxpool2d(conv2) # Pooling\n    \n    # Layer 3\n    conv3 = conv2d(conv2, w['w3'], b['b3']) # Convolution\n    \n    # Layer 4\n    conv4 = conv2d(conv3, w['w4'], b['b4']) # Convolution\n    \n    # Layer 5\n    conv5 = conv2d(conv4, w['w5'], b['b5']) # Convolution\n    conv5 = maxpool2d(conv5) # Pooling\n    \n    # Layer 6\n    fc1 = tf.reshape(conv5, [-1, weights['w6'].get_shape().as_list()[0]]) # Channel Reshape\n    fc1 = tf.add(tf.matmul(fc1, w['w6']), b['b6']) # Linear Function\n    fc1 = tf.nn.relu(fc1) # Activation Function\n    \n    # Layer 7\n    fc2 = tf.add(tf.matmul(fc1, w['w7']), b['b7']) # Linear Function\n    fc2 = tf.nn.relu(fc2) # Activation Function\n    \n    # Layer 8\n    out = tf.add(tf.matmul(fc2, w['w8']), b['b8']) # Linear Function\n    \n    return out",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b278f7408c1186399c8c12212e38967070f498ac"
      },
      "cell_type": "code",
      "source": "logits = alexnet(X, weights, biases) # Forward Propagation",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd7c573ac7acd9a7c6db59ea319e6f4318df0f05"
      },
      "cell_type": "code",
      "source": "# Cost Function\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n# Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n# Training Operation\ntrain_op = optimizer.minimize(loss_op)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f2c43b5e19d15e886864f7dfd8c139aa63f98d8"
      },
      "cell_type": "code",
      "source": "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5184d67f9e547d5846fdd25f6fd12bfc229bacd"
      },
      "cell_type": "code",
      "source": "init = tf.global_variables_initializer()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "311d763affa0f731d378f78a04b0f6e9a9cd5ee5"
      },
      "cell_type": "markdown",
      "source": "## Training the Alexnet"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63829ce38c0d7d785791c6cc842242aef4d1aa02"
      },
      "cell_type": "code",
      "source": "with tf.Session() as sess:\n    # Running Initializer\n    sess.run(init)\n    cost_hist, acc_hist = [], []\n    for epoch in range(1, epochs + 1):\n        _x, _y = next_batch(batch_size, x_train, y_train_encoded)\n        # Running Optimizer\n        sess.run(train_op, feed_dict = { X : _x, Y : _y })\n        if epoch % display_step == 0:\n            # Calculating Loss and Accuracy on the current Epoch\n            loss, acc = sess.run([loss_op, accuracy], feed_dict = { X : _x, Y : _y })\n            loss = loss\n            cost_hist.append(loss)\n            acc_hist.append(acc)\n            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n    W = sess.run(weights)\n    B = sess.run(biases)\n    print('-' * 70)\n    print('\\nOptimization Finished\\n')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f974ea7d9d97722522dc2a2d45247aa8ec35a538"
      },
      "cell_type": "code",
      "source": "plt.plot(list(range(len(cost_hist))), cost_hist)\nplt.title(\"Change in cost\")\nplt.xlabel('Epoch')\nplt.ylabel('Cost')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35031d3d6468191a73124f81f567f20e99cac81a"
      },
      "cell_type": "code",
      "source": "plt.plot(list(range(len(acc_hist))), acc_hist)\nplt.title(\"Change in accuracy\")\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0a60503fda1853f9bc16464dddc5c99bdd6cda8a"
      },
      "cell_type": "markdown",
      "source": "## Saving Optimized Parameters"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6430bb072e0ac48e64a674bf7f5bee1715ac683"
      },
      "cell_type": "code",
      "source": "for key in weights.keys():\n    weights[key] = tf.Variable(W[key])\n    np.save(key, W[key])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b76d097c323f30c71919d08cb99dca9abcf1c9a"
      },
      "cell_type": "code",
      "source": "for key in biases.keys():\n    biases[key] = tf.Variable(B[key])\n    np.save(key, B[key])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e23b335f33fc3cd8fbca4af00f7037c9f8861a2"
      },
      "cell_type": "markdown",
      "source": "## Checking Accuracy"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58f30a54ae4a272ce19c816feeae2f50dc945f57"
      },
      "cell_type": "code",
      "source": "logits = alexnet(X, weights, biases)\ncorrect_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\ninit = tf.global_variables_initializer()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ae06a15bff403f6a68a02fa8b2ad3f32d0caeab"
      },
      "cell_type": "code",
      "source": "with tf.Session() as sess:\n    acc = []\n    sess.run(init)\n    for i in range(100, 29001, 100):\n        acc.append(sess.run(accuracy, feed_dict = { X : x_train[i - 100 : i], Y : y_train_encoded[i - 100 : i] }))\nprint('Accuracy on Training Data: ' + str(sum(acc) * 100 / len(acc)) + '%')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa4e27160b7627c5ea6e7e9acc6d07dc4445d393"
      },
      "cell_type": "code",
      "source": "with tf.Session() as sess:\n    sess.run(init)\n    y_pred = sess.run(logits, feed_dict = { X : x_test })\n    acc = sess.run(accuracy, feed_dict = { X : x_test, Y : y_test_encoded }) * 100\nprint('Accuracy on Test Data: ' + str(acc) + '%')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1e916298081c536084bd270a072c6930b7984c3"
      },
      "cell_type": "markdown",
      "source": "## Visualizing Predictions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "412df66b4e84944b412530f34430ac9d06d25236"
      },
      "cell_type": "code",
      "source": "y_pred = [y_test[list(i).index(max(list(i)))] for i in y_pred]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76e173e163cd133afdd67d254c5aec63cfe32d92"
      },
      "cell_type": "code",
      "source": "display_images(next_batch(12, x_test, y_pred), 'Predictions')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}